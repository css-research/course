# Overview

Due before class May 15th.

# Fork the `hw02` repository

Go [here](https://github.com/css-research/hw02) to fork the repo for homework 02.

# Policy attention

The [Comparative Agendas Project](https://www.comparativeagendas.net) collects and organizes data from archived sources to track policy outcomes across countries. They include data from over 20 nations and U.S. states, covering a range of data sources including legislatures, executives, judiciaries, the press, and public opinion. To identify a unit's policy attention (e.g. legislative bill, presidential speech, judicial decision, newspaper article), the project uses hand-coders to classify the item into one of [23 major policy topics](https://www.comparativeagendas.net/pages/master-codebook). Training and managing research assistants to perform this task is expensive and time-consuming. Can we instead use neural networks to classify each item based on a text description?

# Legislative bills

The [Congressional Bills Project](http://congressionalbills.org/download.html) includes a dataset of every bill/resolution introduced in the U.S. Congress since 1947. `congress_*.csv` contains every bill which has received one of the 24 major policy topics (split into training/validation/test sets), along with the original title of the bill describing its legislative purpose. Your assignment is to construct a deep learning model to correctly classify each bill's major policy topic.

# Major requirements

1. Import the data and tokenize to use with Keras.
    * Keep only the 10000 most frequent words
    * Limit each bill's title to a maximum length of 100 words
    * Pad each sequence to be of length `100`
1. Use a task-specific embedding layer with an appropriate number of output dimensions (select this yourself)
1. Estimate a basic feed-forward network
1. Estimate a recurrent neural network (RNN) with a `layer_simple_rnn`
1. Estimate an RNN with an LSTM layer
1. Estimate an RNN with a GRU layer
1. Estimate five additional neural network models with different configurations of hyperparameters (e.g. number of layers, number of hidden units, dropout, weight regularization, pre-trained word embeddings)
1. For each model, plot the validation loss and accuracy over each epoch.
1. Select the best performing model based on the validation set and evaluate its performance using the test set. Assume that with hand-coding we can achieve a 95% accuracy rate. Would your neural network perform better or worse than hand-coding?

# Estimating your deep learning models

Even more so than last week's assignment, you will need to use a GPU-enhanced computing platform to estimate the necessary models. I recommend using an Amazon AWS EC2 instance as outlined in the textbook. You can use an alternative platform (e.g. Google Cloud, RCC), but I will not offer technical support for any other environment.

# Submission format

* Submit your solution to each part as a separate Jupyter Notebook (if Python) or R Markdown document (if R)


